{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e672bb19",
   "metadata": {},
   "source": [
    "# Exercise: Teach an LLM to Spell with Supervised Fine-Tuning (SFT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e01691a",
   "metadata": {},
   "source": [
    "Large language models (LLMs) are notoriously bad at spelling. This is partly because tokenizers break words into smaller pieces, so the model learns about sub-word units rather than whole words and their spellings.\n",
    "\n",
    "In this exercise, you'll use supervised fine-tuning (SFT) and a technique called Parameter-Efficient Fine-Tuning (PEFT) with Low-Rank Adaptation (LoRA) to teach a small LLM how to spell words. This is a classic example of teaching a model a new skill that isn't well-represented in its pre-training data.\n",
    "\n",
    "## What you'll do in this notebook\n",
    "\n",
    "1.  **Setup**: Import libraries and configure the environment.\n",
    "2.  **Load the tokenizer and base model**: Use a small, instruction-tuned model as our starting point.\n",
    "3.  **Create the dataset**: Generate a simple dataset of words and their correct spellings.\n",
    "4.  **Evaluate the base model**: Test the model's spelling ability *before* fine-tuning to establish a baseline.\n",
    "5.  **Configure LoRA and train**: Attach a LoRA adapter to the model and fine-tune it on the spelling dataset.\n",
    "6.  **Evaluate the fine-tuned model**: Test the model again to see if its spelling has improved."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04085e7",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "id": "97437029",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T22:36:52.643178Z",
     "start_time": "2025-12-24T22:36:52.640404Z"
    }
   },
   "source": [
    "# Setup imports\n",
    "# No changes needed in this cell\n",
    "\n",
    "import os\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    ")\n",
    "from peft import LoraConfig, get_peft_model\n",
    "from trl import SFTTrainer, SFTConfig\n",
    "\n",
    "# Use GPU, MPS, or CPU, in that order of preference\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")  # NVIDIA GPU\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")  # Apple Silicon\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "torch.set_num_threads(max(1, os.cpu_count() // 2))\n",
    "print(\"Using device:\", device)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "id": "18f0a0d7",
   "metadata": {},
   "source": [
    "## Step 1. Load the tokenizer and base model\n",
    "\n",
    "The model `HuggingFaceTB/SmolLM2-135M-Instruct` is a small, instruction-tuned model that's suitable for this exercise. It has 135 million parameters, making it lightweight and efficient for fine-tuning. It's not the most powerful model, but it's a good choice for demonstrating the concepts of SFT and PEFT with LoRA, especially on a CPU or limited GPU resources."
   ]
  },
  {
   "cell_type": "code",
   "id": "f8028ac1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T22:39:43.172872Z",
     "start_time": "2025-12-24T22:39:35.818337Z"
    }
   },
   "source": [
    "# Student task: Load the model and tokenizer, and copy the model to the device.\n",
    "# TODO: Complete the sections with **********\n",
    "\n",
    "# See: https://huggingface.co/docs/transformers/en/models\n",
    "# See: https://huggingface.co/docs/transformers/en/fast_tokenizers\n",
    "\n",
    "# Model ID for SmolLM2-135M-Instruct\n",
    "model_id = \"HuggingFaceTB/SmolLM2-135M-Instruct\"\n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "# Load the model\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id)\n",
    "\n",
    "# Copy the model to the device (GPU, MPS, or CPU)\n",
    "model = model.to(device)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Model parameters (total):\", sum(p.numel() for p in model.parameters()))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model parameters (total): 134515008\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "id": "c6665787",
   "metadata": {},
   "source": [
    "## Step 2. Create the dataset"
   ]
  },
  {
   "cell_type": "code",
   "id": "46de84a5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T22:40:01.978663Z",
     "start_time": "2025-12-24T22:40:01.975968Z"
    }
   },
   "source": [
    "# Create a list of words of different lengths\n",
    "# No changes are needed in this cell.\n",
    "\n",
    "# fmt: off\n",
    "ALL_WORDS = [\n",
    "    \"idea\", \"glow\", \"rust\", \"maze\", \"echo\", \"wisp\", \"veto\", \"lush\", \"gaze\", \"knit\", \"fume\", \"plow\",\n",
    "    \"void\", \"oath\", \"grim\", \"crisp\", \"lunar\", \"fable\", \"quest\", \"verge\", \"brawn\", \"elude\", \"aisle\",\n",
    "    \"ember\", \"crave\", \"ivory\", \"mirth\", \"knack\", \"wryly\", \"onset\", \"mosaic\", \"velvet\", \"sphinx\",\n",
    "    \"radius\", \"summit\", \"banner\", \"cipher\", \"glisten\", \"mantle\", \"scarab\", \"expose\", \"fathom\",\n",
    "    \"tavern\", \"fusion\", \"relish\", \"lantern\", \"enchant\", \"torrent\", \"capture\", \"orchard\", \"eclipse\",\n",
    "    \"frescos\", \"triumph\", \"absolve\", \"gossipy\", \"prelude\", \"whistle\", \"resolve\", \"zealous\",\n",
    "    \"mirage\", \"aperture\", \"sapphire\",\n",
    "]\n",
    "# fmt: on"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "bbeab6e5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T22:43:44.949661Z",
     "start_time": "2025-12-24T22:43:44.943212Z"
    }
   },
   "source": [
    "# Student Task: Create a Hugging Face Dataset with the prompt that asks the model to spell the word\n",
    "# with hyphens between the letters.\n",
    "# TODO: Complete the sections with **********\n",
    "\n",
    "\n",
    "def generate_records():\n",
    "    for word in ALL_WORDS:\n",
    "        yield {\n",
    "            # We will use the SFTTrainer which expects a certain format for prompt and completions pair\n",
    "            # in order for it to automatically construct the right tokenizations to train the model.\n",
    "            # See the documentation for more details:\n",
    "            # https://huggingface.co/docs/trl/en/sft_trainer#expected-dataset-type-and-format\n",
    "            # \"**********\": f\"**********\",\n",
    "            \"prompt\":(\n",
    "                f\"you spell with hyphens between the letters like this W-O-R-D.\\nWord:\\n{word}\\n\\n\"\n",
    "                + \"Spelling:\\n\"\n",
    "            ),\n",
    "            \"completion\": \"-\".join(word).upper() + \".\",  # Of the form W-O-R-D.\n",
    "        }\n",
    "\n",
    "\n",
    "ds = Dataset.from_generator(generate_records)\n",
    "\n",
    "# Show the first item\n",
    "ds[0]"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prompt': 'you spell with hyphens between the letters like this W-O-R-D.\\nWord:\\nidea\\n\\nSpelling:\\n',\n",
       " 'completion': 'I-D-E-A.'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "120b63d3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T22:44:52.197386Z",
     "start_time": "2025-12-24T22:44:52.191404Z"
    }
   },
   "source": [
    "# Student Task: Split the dataset into training and testing sets\n",
    "# See: train_test_split\n",
    "# TODO: Complete the sections with **********\n",
    "\n",
    "ds = ds.train_test_split(test_size=0.25,seed=42)  # Set the test set to be 25% of the dataset, and the rest is training\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "8c68fbd9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T22:44:54.689993Z",
     "start_time": "2025-12-24T22:44:54.687947Z"
    }
   },
   "source": [
    "# View the training set\n",
    "# No changes needed in this cell\n",
    "\n",
    "ds[\"train\"]"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['prompt', 'completion'],\n",
       "    num_rows: 46\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "id": "4b6a9436",
   "metadata": {},
   "source": [
    "## Step 3. Evaluate the base model\n",
    "\n",
    "Before we fine-tune the model, let's see how it performs on the spelling task. We'll create a helper function to generate a spelling for a given word and compare it to the correct answer."
   ]
  },
  {
   "cell_type": "code",
   "id": "6581c243",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-25T00:02:05.413108Z",
     "start_time": "2025-12-25T00:02:04.857088Z"
    }
   },
   "source": [
    "# Student task: Create a function to check the model's spelling.\n",
    "# This function will take a model, tokenizer, prompt, and the correct spelling.\n",
    "# It should generate text from the model and compare the model's proposed spelling\n",
    "# to the actual spelling, returning the proportion of characters that were correct.\n",
    "# TODO: Complete the sections with **********\n",
    "\n",
    "\n",
    "def check_spelling(\n",
    "    model, tokenizer, prompt: str, actual_spelling: str, max_new_tokens: int = 20\n",
    ") -> (str, str):\n",
    "    # Tokenize the prompt\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "\n",
    "    # Generate text from the model\n",
    "    gen = model.generate(**inputs, max_new_tokens=max_new_tokens, use_cache =False)\n",
    "\n",
    "    # Decode the generated tokens to a string\n",
    "    output = tokenizer.decode(gen[0], skip_special_tokens=True)\n",
    "\n",
    "    # Extract the generated spelling from the full output string\n",
    "    proposed_spelling = output.split(\"Spelling:\")[-1].strip()\n",
    "\n",
    "\n",
    "    # strip any whitepsace from the actual spelling\n",
    "    actual_spelling = actual_spelling.strip()\n",
    "\n",
    "\n",
    "    # Remove hyphens for a character-by-character comparison\n",
    "    proposed_spelling = proposed_spelling.lower()\n",
    "    actual_spelling = actual_spelling.replace(\"-\", \" \")\n",
    "\n",
    "    # Calculate the number of correct characters\n",
    "    num_correct = sum(1 for a,b in zip(actual_spelling,proposed_spelling) if a == b)\n",
    "\n",
    "\n",
    "    print(\n",
    "        f\"Proposed: {proposed_spelling} | Actual: {actual_spelling} \"\n",
    "        f\"| Matches: {'‚úÖ' if proposed_spelling == actual_spelling else '‚ùå'}\"\n",
    "    )\n",
    "\n",
    "    return num_correct / len(actual_spelling)  # Return proportion correct\n",
    "\n",
    "\n",
    "check_spelling(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    prompt=ds[\"test\"][0][\"prompt\"],\n",
    "    actual_spelling=ds[\"test\"][0][\"completion\"],\n",
    ")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proposed: wry | Actual: W R Y L Y. | Matches: ‚ùå\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "id": "7642646c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-25T00:02:48.412465Z",
     "start_time": "2025-12-25T00:02:38.728084Z"
    }
   },
   "source": [
    "# Student task: Evaluate the base model's spelling ability\n",
    "# We expect it to perform poorly, as it hasn't been trained for this task.\n",
    "\n",
    "proportion_correct = 0.0\n",
    "\n",
    "for example in ds[\"train\"].select(range(20)):\n",
    "    prompt = example[\"prompt\"]\n",
    "    completion = example[\"completion\"]\n",
    "    result = check_spelling(\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        prompt=prompt,\n",
    "        actual_spelling=completion,\n",
    "        max_new_tokens=20,\n",
    "    )\n",
    "    proportion_correct += result\n",
    "\n",
    "print(f\"{proportion_correct}/20.0 words correct\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proposed: sphinx | Actual: S P H I N X. | Matches: ‚ùå\n",
      "Proposed: brawn | Actual: B R A W N. | Matches: ‚ùå\n",
      "Proposed: goss | Actual: G O S S I P Y. | Matches: ‚ùå\n",
      "Proposed: - en-chant\n",
      "\n",
      "spelling | Actual: E N C H A N T. | Matches: ‚ùå\n",
      "Proposed: tavern | Actual: T A V E R N. | Matches: ‚ùå\n",
      "Proposed: whistle | Actual: W H I S T L E. | Matches: ‚ùå\n",
      "Proposed: w-o-r-d\n",
      "\n",
      "how would you like to see the word changed? | Actual: C A P T U R E. | Matches: ‚ùå\n",
      "Proposed: echo\n",
      "\n",
      "word:\n",
      "echo | Actual: E C H O. | Matches: ‚ùå\n",
      "Proposed: mirth | Actual: M I R T H. | Matches: ‚ùå\n",
      "Proposed: cris | Actual: C R I S P. | Matches: ‚ùå\n",
      "Proposed: zeal | Actual: Z E A L O U S. | Matches: ‚ùå\n",
      "Proposed: ember\n",
      "\n",
      "how many words does the word \"ember\" contain? | Actual: E M B E R. | Matches: ‚ùå\n",
      "Proposed: scarab | Actual: S C A R A B. | Matches: ‚ùå\n",
      "Proposed: knit\n",
      "\n",
      "how many times does the word \"knit\" appear in the following sentence:\n",
      "w | Actual: K N I T. | Matches: ‚ùå\n",
      "Proposed: resolve\n",
      "\n",
      "how many times does the word resolve occur in the english language? | Actual: R E S O L V E. | Matches: ‚ùå\n",
      "Proposed: velvet | Actual: V E L V E T. | Matches: ‚ùå\n",
      "Proposed: absolve | Actual: A B S O L V E. | Matches: ‚ùå\n",
      "Proposed: lunar | Actual: L U N A R. | Matches: ‚ùå\n",
      "Proposed: maze | Actual: M A Z E. | Matches: ‚ùå\n",
      "Proposed: summit | Actual: S U M M I T. | Matches: ‚ùå\n",
      "0.07142857142857142/20.0 words correct\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "id": "e7c6563f",
   "metadata": {},
   "source": [
    "As expected, the base model is terrible at spelling. It mostly just repeats the word back. Now, let's fine-tune it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e7ef15",
   "metadata": {},
   "source": [
    "## Step 4. Configure LoRA and train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403a39e8",
   "metadata": {},
   "source": [
    "Let‚Äôs attach a LoRA adapter to the base model. We use a LoRA config so only a tiny fraction of parameters are trainable. Read more here: [LoRA](https://huggingface.co/docs/peft/main/en/conceptual_guides/lora)."
   ]
  },
  {
   "cell_type": "code",
   "id": "d1b8d596",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-25T00:09:43.616843Z",
     "start_time": "2025-12-25T00:09:43.526613Z"
    }
   },
   "source": [
    "from peft import TaskType\n",
    "\n",
    "# Student task: Configure LoRA for a causal LM and wrap the model with get_peft_model\n",
    "# Complete the sections with **********\n",
    "\n",
    "# Print how many params are trainable at first\n",
    "trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "total = sum(p.numel() for p in model.parameters())\n",
    "print(\n",
    "    f\"Trainable params BEFORE: {trainable:,} / {total:,} ({100 * trainable / total:.2f}%)\"\n",
    ")\n",
    "\n",
    "# See: https://huggingface.co/docs/peft/package_reference/lora\n",
    "lora_config = LoraConfig(\n",
    "    r=8      ,           # Rank of the update matrices. Lower value = fewer trainable parameters.\n",
    "    lora_alpha=16   ,     # LoRA scaling factor.\n",
    "    lora_dropout=0.05,      # Dropout probability for LoRA layers.\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.CAUSAL_LM,         # Causal Language Modeling.\n",
    ")\n",
    "# # Wrap the base model with get_peft_model\n",
    "model = get_peft_model(model, lora_config)\n",
    "\n",
    "\n",
    "# Print the number of trainable parameters after applying LoRA\n",
    "trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "total = sum(p.numel() for p in model.parameters())\n",
    "print(\n",
    "    f\"Trainable params AFTER: {trainable:,} / {total:,} ({100 * trainable / total:.2f}%)\"\n",
    ")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable params BEFORE: 134,515,008 / 134,515,008 (100.00%)\n",
      "Trainable params AFTER: 460,800 / 134,975,808 (0.34%)\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "markdown",
   "id": "30c5e91b",
   "metadata": {},
   "source": [
    "Now let‚Äôs set the training arguments. We'll use `SFTConfig` from the TRL library, which is a wrapper around the standard `TrainingArguments`. We keep epochs, batch size, and sequence length modest to finish training quickly."
   ]
  },
  {
   "cell_type": "code",
   "id": "9341ba79",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-25T00:19:44.114570Z",
     "start_time": "2025-12-25T00:19:44.111746Z"
    }
   },
   "source": [
    "# Student task: Fill in the SFTConfig for a quick training run\n",
    "# Complete the sections with **********\n",
    "\n",
    "output_dir = \"data/model\"\n",
    "\n",
    "# See: https://huggingface.co/docs/trl/en/sft_trainer#trl.SFTConfig\n",
    "training_args = SFTConfig(\n",
    "    output_dir=output_dir,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    gradient_accumulation_steps=2,\n",
    "    num_train_epochs=20,\n",
    "    learning_rate=5 * 1e-4,\n",
    "    logging_steps=20,\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=20,\n",
    "    save_strategy=\"no\",\n",
    "    report_to=[],                            # disable wandb/tensorboard\n",
    "    fp16=False,                              # stay in fp32 for CPU/MPS\n",
    "    lr_scheduler_type=\"cosine\",\n",
    ")\n"
   ],
   "outputs": [],
   "execution_count": 24
  },
  {
   "cell_type": "markdown",
   "id": "30d14200",
   "metadata": {},
   "source": [
    "Now we define the `SFTTrainer` and run the fine-tuning process."
   ]
  },
  {
   "cell_type": "code",
   "id": "011a4855",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-25T00:20:25.265106Z",
     "start_time": "2025-12-25T00:19:47.503836Z"
    }
   },
   "source": [
    "# Student Task: Create and run the SFTTrainer\n",
    "# TODO: Complete the sections with **********\n",
    "\n",
    "\n",
    "# See: https://huggingface.co/docs/trl/en/sft_trainer\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=ds[\"train\"],\n",
    "    eval_dataset=ds[\"test\"],\n",
    "    args=training_args,\n",
    ")\n",
    "# Now train it:\n",
    "trainer.train()\n"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='120' max='120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [120/120 00:35, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Entropy</th>\n",
       "      <th>Num Tokens</th>\n",
       "      <th>Mean Token Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.410400</td>\n",
       "      <td>0.575742</td>\n",
       "      <td>1.789996</td>\n",
       "      <td>6473.000000</td>\n",
       "      <td>0.831069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.192800</td>\n",
       "      <td>0.613704</td>\n",
       "      <td>1.487747</td>\n",
       "      <td>12948.000000</td>\n",
       "      <td>0.852582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.075400</td>\n",
       "      <td>0.709228</td>\n",
       "      <td>1.313572</td>\n",
       "      <td>19340.000000</td>\n",
       "      <td>0.810714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.027500</td>\n",
       "      <td>0.775368</td>\n",
       "      <td>1.238472</td>\n",
       "      <td>25819.000000</td>\n",
       "      <td>0.810135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.017400</td>\n",
       "      <td>0.802979</td>\n",
       "      <td>1.232425</td>\n",
       "      <td>32272.000000</td>\n",
       "      <td>0.800070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.015700</td>\n",
       "      <td>0.793058</td>\n",
       "      <td>1.223765</td>\n",
       "      <td>38680.000000</td>\n",
       "      <td>0.799265</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=120, training_loss=0.12322785953680675, metrics={'train_runtime': 36.2759, 'train_samples_per_second': 25.361, 'train_steps_per_second': 3.308, 'total_flos': 26372523967488.0, 'train_loss': 0.12322785953680675, 'epoch': 20.0})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 25
  },
  {
   "cell_type": "markdown",
   "id": "e30c443c",
   "metadata": {},
   "source": [
    "## Step 5. Evaluate the fine-tuned model"
   ]
  },
  {
   "cell_type": "code",
   "id": "6f806e1d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-25T00:22:32.545765Z",
     "start_time": "2025-12-25T00:22:27.109929Z"
    }
   },
   "source": [
    "# Evaluate the fine-tuned model on the same training examples\n",
    "# No changes needed in this cell\n",
    "\n",
    "\n",
    "proportion_correct = 0.0\n",
    "\n",
    "for example in ds[\"train\"].select(range(20)):\n",
    "    prompt = example[\"prompt\"]\n",
    "    completion = example[\"completion\"]\n",
    "    result = check_spelling(\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        prompt=prompt,\n",
    "        actual_spelling=completion,\n",
    "        max_new_tokens=20,\n",
    "    )\n",
    "    proportion_correct += result\n",
    "\n",
    "print(f\"{proportion_correct}/20.0 words correct\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proposed: s-p-h-i-n-x. | Actual: S P H I N X. | Matches: ‚ùå\n",
      "Proposed: b-r-a-w-n. | Actual: B R A W N. | Matches: ‚ùå\n",
      "Proposed: g-o-s-s-i-p-y. | Actual: G O S S I P Y. | Matches: ‚ùå\n",
      "Proposed: e-n-c-h-a-n-t. | Actual: E N C H A N T. | Matches: ‚ùå\n",
      "Proposed: t-a-v-e-r-n. | Actual: T A V E R N. | Matches: ‚ùå\n",
      "Proposed: w-h-i-s-t-l-e. | Actual: W H I S T L E. | Matches: ‚ùå\n",
      "Proposed: c-a-p-t-u-r-e. | Actual: C A P T U R E. | Matches: ‚ùå\n",
      "Proposed: e-c-h-o. | Actual: E C H O. | Matches: ‚ùå\n",
      "Proposed: m-i-r-t-h. | Actual: M I R T H. | Matches: ‚ùå\n",
      "Proposed: c-r-i-s-p. | Actual: C R I S P. | Matches: ‚ùå\n",
      "Proposed: z-e-a-l-o-u-s. | Actual: Z E A L O U S. | Matches: ‚ùå\n",
      "Proposed: e-m-b-e-r. | Actual: E M B E R. | Matches: ‚ùå\n",
      "Proposed: s-c-a-r-a-b. | Actual: S C A R A B. | Matches: ‚ùå\n",
      "Proposed: k-n-i-t. | Actual: K N I T. | Matches: ‚ùå\n",
      "Proposed: r-e-s-o-l-v-e. | Actual: R E S O L V E. | Matches: ‚ùå\n",
      "Proposed: v-e-l-v-e-t. | Actual: V E L V E T. | Matches: ‚ùå\n",
      "Proposed: a-b-s-o-l-v-e. | Actual: A B S O L V E. | Matches: ‚ùå\n",
      "Proposed: l-u-n-a-r. | Actual: L U N A R. | Matches: ‚ùå\n",
      "Proposed: m-a-z-e. | Actual: M A Z E. | Matches: ‚ùå\n",
      "Proposed: s-u-m-m-i-t. | Actual: S U M M I T. | Matches: ‚ùå\n",
      "1.7916666666666663/20.0 words correct\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "cell_type": "markdown",
   "id": "3bbfe48f",
   "metadata": {},
   "source": [
    "The model now performs better on the training data it has seen. But has it generalized? Let's check its performance on the unseen test set."
   ]
  },
  {
   "cell_type": "code",
   "id": "af0bab9d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-25T00:22:46.719853Z",
     "start_time": "2025-12-25T00:22:42.052767Z"
    }
   },
   "source": [
    "# Evaluate the fine-tuned model on the unseen test set\n",
    "# No changes needed in this cell\n",
    "\n",
    "\n",
    "proportion_correct = 0.0\n",
    "num_examples = len(ds[\"test\"])\n",
    "\n",
    "for example in ds[\"test\"]:\n",
    "    prompt = example[\"prompt\"]\n",
    "    completion = example[\"completion\"]\n",
    "    result = check_spelling(\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        prompt=prompt,\n",
    "        actual_spelling=completion,\n",
    "        max_new_tokens=20,\n",
    "    )\n",
    "    proportion_correct += result\n",
    "\n",
    "print(f\"{proportion_correct}/{num_examples}.0 words correct\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proposed: w-r-i-y-l-i-y. | Actual: W R Y L Y. | Matches: ‚ùå\n",
      "Proposed: g-l-i-n-e-s. | Actual: G L I S T E N. | Matches: ‚ùå\n",
      "Proposed: c-a-s-e. | Actual: Q U E S T. | Matches: ‚ùå\n",
      "Proposed: c-r-e-e-v-e. | Actual: C R A V E. | Matches: ‚ùå\n",
      "Proposed: l-u-s-i-o-n. | Actual: L U S H. | Matches: ‚ùå\n",
      "Proposed: f-a-l-i-c-e. | Actual: F A B L E. | Matches: ‚ùå\n",
      "Proposed: k-n-a-r-k-t. | Actual: K N A C K. | Matches: ‚ùå\n",
      "Proposed: t-r-i-v-h-p-l-e. | Actual: T R I U M P H. | Matches: ‚ùå\n",
      "Proposed: s-a-p-l-i-c-h. | Actual: S A P P H I R E. | Matches: ‚ùå\n",
      "Proposed: e-x-p-s-t. | Actual: E X P O S E. | Matches: ‚ùå\n",
      "Proposed: f-s-r-e-c-o-s-n. | Actual: F R E S C O S. | Matches: ‚ùå\n",
      "Proposed: w-i-p-s. | Actual: W I S P. | Matches: ‚ùå\n",
      "Proposed: m-i-r-g-e. | Actual: M I R A G E. | Matches: ‚ùå\n",
      "Proposed: i-v-o-r-y. | Actual: I V O R Y. | Matches: ‚ùå\n",
      "Proposed: o-n-s-i-d-r-w. | Actual: O N S E T. | Matches: ‚ùå\n",
      "Proposed: e-l-u-d-e. | Actual: E L U D E. | Matches: ‚ùå\n",
      "0.325/16.0 words correct\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "cell_type": "markdown",
   "id": "7b02ba61",
   "metadata": {},
   "source": [
    "It looks like it has improved! Perhaps with a larger dataset and more training, it could get even better."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed16c690",
   "metadata": {},
   "source": [
    "## Congratulations for completing the exercise! üéâ\n",
    "\n",
    "‚úÖ You did it! You successfully fine-tuned a small language model using PEFT with LoRA to teach it a new skill: spelling! You saw how the base model failed completely at the task, and with a very small amount of data and a short training run, the model managed to get better at spelling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f093a0b",
   "metadata": {},
   "source": [
    "<br /><br /><br /><br /><br /><br /><br /><br /><br />"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
